---
title: Saturday, 2019-08-17 {#2019817:S}
---
One can accomplish some form of the MCTS stuff we thought about
yesterday by weight tying. We have three "components"

1.  A neural network, with the weights factorized out as input, which
    assigns a move and a win probability (or whatever) to a Go position.

2.  An agent with the same input, which does the same thing, but
    augmented by MCTS.

3.  A unit which holds the weights

Wired up in such a way that 1. and 2. share the weights, the weights are
updated based on training data from 1., and for each step, 1. is trained
on the output of 2.

There are some issues on this approach (we should read up on the
specific architecture of AlphaGo Zero), but the main one is that the
implementation of the neural network has to be duplicated between the
MCTS node and the network itself. I want a diagram where one can just
plug in any "compatible" agent and get "this but with MCTS".
