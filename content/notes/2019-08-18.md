---
title: Untitled
date: 2019-08-18
---
FLOP
----

I am reading the analysis of the harmonic oscillator in the Feynman
lectures on physics, starting at chapter 21. I will reproduce some
things here.

In general, we are solving the differential equation
$$mx''(t) = -kx(t) + F(t),$$ where $x: \bR \to \bR$ is the motion of our
system and $F: \bR \to \bR$ is the *driving force*. We consider the case
of an oscillating force $F(t) = F_0 \cos \omega t$. Looking for periodic
solutions with the same frequency as the force, we try
$$x(t) = C \cos \omega t$$ and try to solve for the constant. We get
$$-m\omega^2 C \cos \omega t = -kC\cos \omega t + F_0 \cos \omega t$$
Dividing out the $\cos$, we get $$-m\omega^2 C = -kC + F_0$$

First, suppose $F_0 = 0$, so that there is no force. Then the equation
is also independent of $C$: a "free" harmonic oscillator can oscillate
at any amplitude. We also see that $k = m\omega^2$ - in other words, the
frequency of the oscillation (if there is no driving force) is always
given by $\sqrt{k/m}$. Let us denote this frequency by $\omega_0$.

Now for the general case, let us sub in $k = m\omega_0^2$ and solve the
equation: $$C = F_0/m(\omega_0^2 - \omega^2)$$ So the amplitude of the
oscillation is proportional to the force, inversely proportional to the
mass, and is larger if the frequency of the force is close to the
natural frequency.

If $\omega_0 = \omega$, there is no solution of this form unless $F_0=0$
(essentially because $x$ escapes to infinity).

I want to make a note of the essential features that make FLOP a good
(series of) textbooks, so that I can try to use them to identify other
good textbooks.

-   It is *accessible*. It's very easy to read.

-   Nevertheless, it is *deep* - it is a serious textbook which gives a
    detailed explanation of the topics it covers.

-   It is *comprehensive* - it covers a wide variety of topics, and goes
    quite far into what was "modern physics" at the time.

These are all just "doubleplusgood" features - so far, I may as well
just have said "it is a really good textbook". Let us try to say
something about what makes it special.

-   It is *clear*. It does not pretend that opaque ideas are natural, or
    that simple things are complicated. It really gets across the point
    that physical ideas are *not* mystical, but rather the exact
    opposite.

-   It gives an idea of how to derive things "from scratch" - but not in
    a mathematical sense of building things from axioms, but rather,
    where do the equations come from? The importance here is not that
    things are presented historically, but that you get some sense of
    how physical ideas can be developed.

Spivak's operads for SOS
------------------------

Thinking about Spivak's viewpoint of operads as specifying wiring
diagrams. How feasible would it be to "put this in a computer", i.e to
build a machine which puts in a specification of an operad (+ some
graphical info) and you get a GUI for wiring diagrams, where you can
then print (some code specifying) how the corresponding element is built
using the operad operations?

![A wiring diagram](/images/screenshot_spivak_opd.png)

This picture describes a $5$-ary morphism in some operad (because there
are five boxes), of "input arity" $(1,3), (2,1), (3,2), (2,1), (0,2)$
(because those are the numbers input/output ports on the boxes), and
"output arity" $(2,3)$. The dotted lines describe how to build this
morphism as the composite of a $3$-ary (or rather,
$(1,3),(2,1),(3,2)$-ary) morphism and a $2$-ary (or $(2,1),(0,2)$-ary)
morphism, into a $2$-ary one.

(This picture is from [@SSV16])

Maybe to spell out the general approach: if we have a notion of wiring
diagram, we create an operad where the *morphisms* are wiring diagrams
(with holes for other wiring diagrams), and the types/colors are the
possible "type signatures", or the possible sets of "outside terminals"
- the information telling you which wiring diagrams fit in which holes.

As far as I can tell, the business with time in [@SSV16] is that we can
label each "terminal" with an object from some chosen category $\cC$. If
we put $\cC = \Set$, we get boxes with terminals where each terminal has
a specified set of outputs/inputs. If instead we choose something like
$\Fun(\bN, \Set)$, we get boxes where each terminal has a *time-varying*
set of outputs/inputs (but these must match up, of course). (It seems
maybe we will do something more sophisticated, I have not read the paper
yet, but I guess this is the idea).

Essential features of probability theory
----------------------------------------

At some point I want to write "Probability from a categorical viewpoint"
(or some such title.) I list some essential theorems/constructions of
probability theory:

1.  Random variables, distributions, joint distributions, etc.

2.  Covariance of random variable

3.  Conditional distributions, conditional expectations.

4.  Law of large numbers-type results.

5.  Central limit theorems

6.  Martingales?

We should open a book on probability theory for this. What is the
connection of Wasserstein distance to relative entropy/mutual
information?
