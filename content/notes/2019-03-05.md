---
title: Untitled
date: 2019-03-05
tags: Categorical probability, Giry monad, Markov kernels
---
Given measurable spaces $X,Y$, we have two notions of "stochastic map"
$X \to Y$:

A *Giry map* $X \to Y$ is a measurable function $$X \to GY$$ where $GY$
is the set of probability measures on $Y$, equipped with the
sigma-algebra generated by the evaluation maps.

A *Markov kernel* $X \to Y$ is a function
$$f: X \times \Sigma_Y \to [0,1]$$ with the properties that

(1) For each $x\in X$, the map $U \mapsto f(x,U)$ is a probability
    measure on $Y$.

(2) For each $U \in \Sigma_Y$, the map $x \mapsto f(x,U)$ is a
    measurable function $X \to [0,1]$

There are more general types of kernels where we relax the conditions of
the measures in (1), and allow greater values of $f$.

Given a Markov kernel $f: X \times \Sigma_Y \to [0,1]$, we may define a
Giry map by $x \mapsto f(x,-)$. This determines a bijection between the
collection of Giry maps and the collection of Markov kernels $X \to Y$.

The collection of Giry maps can be identifies with a subset of the set
$$\Hom_{\Set}(X\times \Sigma_y, [0,1]) \simeq \Hom_{\Set}(X, \Hom(\Sigma_Y,[0,1]))$$
And the map defined in the proposition is precisely this equivalence. So
it suffices to verify that the conditions defining Giry maps and Markov
kernels are equivalent under this identification. This is just a matter
of writing out the definitions.

We may consider some different categories which could support useful
"Giry monads"

(a) The category of measurable spaces (as above).

(b) The category of compact Hausdorff spaces.

(c) The category of general hausdorff spaces (maybe we require the
    measure to "vanish at infinity" in some sense). Maybe require
    paracompactness?

A $G$-algebra encompasses at least a convex structure on the underlying
set, given by evaluating linear combinations of dirac measures.

We denote by $\CHaus$ the category of compact Hausdorff spaces and
continuous maps. Given $X \in \CHaus$, let $GX$ denote the collection of
Borel probability measures on $X$.

Observe/recall that any probability measure on a compact Hausdorff space
is regular, so by the Riesz representation theorem, we may identify $GX$
with a certain subset of $C(X)^*$ - namely those functionals which are
positive and satisfy $\lambda(1_X) = 1$. We claim this space is compact.
Positive functionals satisfy $\lambda(f) \leq \lambda(g)$ if $f\leq g$
everywhere. Hence $\lambda(f) \leq 1$ if $\sup f \leq 1$ for
$\lambda \in GX$. On the other hand, $\norm{\lambda} = 1$ if and only if
there exists some $f \leq 1$ with $\lambda(f) = 1$. But if this is true,
then also $\lambda(1) = 1$ - and vice versa, so that
$$GX = \{\lambda \in C(X)^* \mid \lambda \geq 0, \norm{\lambda} = 1.$$
This is a closed subspace of the closed unit ball, so by Banach-Alaoglu,
it is compact.

It's clear that $X \mapsto GX$ defines a functor $\CHaus \to \CHaus$.

We define a natural transformation $\eta_X: X \to GX$ by
$\eta_X (x)(f) = f(x)$. Continuity is easy to verify.

Now let's define $\mu_X : G^2X \to GX$. $G^2X \subset C(GX)^*$.

Let $\alpha \in G^2X$. Then we must define
$\mu_X(\alpha) \in GX \subset C(X)^*$. That is, we must define
$\mu_X(\alpha)(f) \in \C$. We will do this by applying $\alpha$ to an
element of $C(GX)$. Given $\rho \in GX$, we can apply $\rho$ to $f$ to
produce a complex number. This defines an evaluation map
$\ev_f \in C(GX)$. We define $\mu_X(\alpha)(f) = \alpha(\ev_f)$.

By writing out the equations, we can see that this defines a monad
structure on $G$.

The category of modules over the Giry monad on $\CHaus$ is equivalent to
the category of convex compact Hausdorff spaces. (i.e, spaces with a
convex structure so that the maps are continuous).

Given a Giry module, we can produce a convex structure on the underlying
space by applying the structure map $GX \to X$ to convex combinations of
dirac measures.

First, we claim that for a Giry module $\pi: GX \to X$, the map
$(\alpha, x, y) \mapsto \pi(\alpha \delta_x + (1-\alpha)\delta_y)$ is a
continuous map $$[0,1] \times X \times X \to X$$ This is a consequence
of the continuity of these operations in $GX$, which is a convex subset
of a topological vector space.

Now we claim that all continuous convex structures on $X$ arise in this
way, in a unique way. Suppose we have a convex structure on $X$, and an
element $\mu \in GX \subset C(X)^*$. We must produce an element of $X$.
Seems this should require some sort of completeness? Might need
something more for this proposition.

It seems that Polish space is a good class of topological spaces to work
in?

In the Bayesian perspective, a (parameterized) model is a stochastic map
from parameter space to a collection of probability distributions. - So
in some sense, it is twice-stochastic? A frequentist model is just a map
from parameter space to probability distributions.

Given an outcome space $X$ and a map $X \to Y$, and a point $y \in Y$,
which model is the fiber inside $X$? - This is not interesting, it's
just the subset of $X$ which is "dirac at $y$".

Can we describe conditioning on the outcome of an experiment
categorically?

We can describe a map $\Hom(X,GY) \times GX \to G(X\times Y)$ as
follows:
$$GX \times \Hom(X,GY) \to GX \times \Hom(X, GX \times GY) \to GX \times \Hom(X, G(X\times Y)) \to G(X\times Y)$$
After this, given $y \in Y$, we can condition normally to obtain a
distribution on $X$. This describes conditioning on the outcome of an
experiment.
